{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DlrmluRfNayp"
   },
   "source": [
    "First, we install the lyricsgenius API, as well as multiprocess to increase speed of data scraping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2v6oNAIxM1TN",
    "outputId": "0912025a-a0ea-47e6-8445-0e0c3cb6360c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: multiprocess in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (0.70.12.2)\n",
      "Requirement already satisfied: dill>=0.3.4 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from multiprocess) (0.3.4)\n",
      "Requirement already satisfied: lyricsgenius in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: requests>=2.20.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from lyricsgenius) (2.26.0)\n",
      "Requirement already satisfied: beautifulsoup4>=4.6.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from lyricsgenius) (4.10.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from beautifulsoup4>=4.6.0->lyricsgenius) (2.3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from requests>=2.20.0->lyricsgenius) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from requests>=2.20.0->lyricsgenius) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from requests>=2.20.0->lyricsgenius) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from requests>=2.20.0->lyricsgenius) (3.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install multiprocess\n",
    "!pip install lyricsgenius"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the libraries and set a path for our input file of artists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "AwPBO5kVbh-h"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import multiprocess\n",
    "import queue\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "from requests.exceptions import HTTPError, ConnectionError, RequestException\n",
    "from lyricsgenius import Genius\n",
    "\n",
    "\n",
    "# OS agnostic\n",
    "import os \n",
    "CSV_PATH = os.path.join(os.path.curdir, 'artists', '10000-MTV-Music-Artists-page-%s.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PjAsUT5ZOSex"
   },
   "source": [
    "# Scrape Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set up a lyricsgenius token, and use the API to pull the lyrics data for each artist in the dataset for the top 10,000 artists from MTV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "7zBQzXBJNabo"
   },
   "outputs": [],
   "source": [
    "# Genius setup\n",
    "             \n",
    "def genius_setup():\n",
    "    token = \"EBufquOcw_ts4Y4V7yiddUNyUakTdqCpnMZhiI3XtAScWOntEom8Hj4T87gAV_cA\"\n",
    "    genius = Genius(token, retries=2)\n",
    "\n",
    "    genius.verbose = False\n",
    "    genius.remove_section_headers = True\n",
    "    genius.skip_non_songs = True\n",
    "    genius.excluded_terms = [\"(Remix)\", \"(Live)\"]\n",
    "\n",
    "    return genius    \n",
    "\n",
    "\n",
    "# Multiprocessing cores\n",
    "process_number = int(multiprocess.cpu_count()) * 2\n",
    "\n",
    "# Data management\n",
    "final_ = multiprocess.Manager().list()\n",
    "\n",
    "# artist_queue = queue.Queue()\n",
    "# final_ = []\n",
    "checked_artists = set()\n",
    "\n",
    "file_name = \"song_data_2.csv\"\n",
    "\n",
    "\n",
    "# Pull out artists\n",
    "def get_artists(queue):\n",
    "    for x in range(1,5):\n",
    "        path = CSV_PATH % str(x)\n",
    "        with open(path, encoding=\"UTF-8\") as csvfile:\n",
    "            TopArtists = csv.reader(csvfile)\n",
    "            \n",
    "            # Skip header\n",
    "            next(TopArtists)\n",
    "            for row in TopArtists:\n",
    "                artist = row[0]\n",
    "                # Check if we should skip this artists since we already found the data\n",
    "                if artist not in checked_artists:\n",
    "                    queue.put(artist)\n",
    "\n",
    "\n",
    "# File management\n",
    "def write_to_csv(data):\n",
    "    \"\"\"\n",
    "    data: list of dictionaries {artist, song, data}\n",
    "    \"\"\"\n",
    "    global file_name\n",
    "    \n",
    "    csv_path = os.path.join(os.path.curdir, 'data', file_name)\n",
    "    with open(csv_path, 'w') as csv_file: \n",
    "        # creating a csv dict writer object \n",
    "        print(\"Entries: {num}\".format(num=len(data)))\n",
    "        keys = data[0].keys()\n",
    "        writer = csv.DictWriter(csv_file, fieldnames = keys) \n",
    "        \n",
    "        # writing headers (field names) \n",
    "        writer.writeheader() \n",
    "        \n",
    "        # writing data rows \n",
    "        writer.writerows(data) \n",
    "        \n",
    "\n",
    "def read_csv():\n",
    "    global final_, checked_artists, file_name   \n",
    "    \n",
    "    csv_path = os.path.join(os.path.curdir, 'data', file_name)\n",
    "    \n",
    "    # opening the CSV file\n",
    "    try:\n",
    "        with open(csv_path, mode ='r', encoding=\"UTF-8\") as file:   \n",
    "\n",
    "            # reading the CSV file\n",
    "            data = csv.DictReader(file)\n",
    "\n",
    "            for entry in data:\n",
    "                checked_artists.add(entry[\"artist\"])\n",
    "                final_.append(entry)\n",
    "                \n",
    "        print(\"Number of artists already found {num}\".format(num=len(checked_artists)))\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    \n",
    "\n",
    "# Run genius search\n",
    "def search_genius(args):\n",
    "    import sys\n",
    "    from requests.exceptions import RequestException\n",
    "    artist_queue, num, genius, final_ = args\n",
    "    \n",
    "    def log(string):\n",
    "        print(\"[{num}] \".format(num=num) + string + \"\\n\", end='')\n",
    "        sys.stdout.flush()\n",
    "    \n",
    "    # Processing\n",
    "    def clean_data(data):\n",
    "        cleaned_data = data.replace(\"\\n\", \"|\").replace(\",\", \" \")\n",
    "        return cleaned_data\n",
    "\n",
    "    def process_artist(artist):\n",
    "        artist_dict = artist.to_dict()\n",
    "        return \"\"\n",
    "\n",
    "    def process_song(song):\n",
    "        lyrics = clean_data(song.lyrics)\n",
    "        return lyrics\n",
    "\n",
    "    def build_entry(artist, song, data, columns = [\"artist\", \"song\", \"data\"]):\n",
    "        entry = {\"artist\": artist, \"song\": song, \"data\": data}\n",
    "        return entry\n",
    "    \n",
    "    log(\"Starting\")\n",
    "    try:\n",
    "        while True:\n",
    "            genius_artist = None\n",
    "            artist = artist_queue.get()\n",
    "            if artist is None:\n",
    "                log(\"Done\")\n",
    "                return\n",
    "            log(\"Remaining: [{queue}]. Searching {artist}\".format(queue=artist_queue.qsize(), artist=artist.strip()))\n",
    "            \n",
    "            # Pull data for artist from genius\n",
    "            for x in range(5):\n",
    "                try:\n",
    "                    genius_artist = genius.search_artist(artist, per_page=50, get_full_info=False)\n",
    "                    break\n",
    "                except RequestException as e:\n",
    "                    log(\"HTTPSConnectionPool exception. Attempt {}/5\".format(x+1))\n",
    "                except Exception as e:\n",
    "                    log(\"Exception. Attempt {}/3\".format(x+1))\n",
    "            \n",
    "            log(\"Finished {artist}\".format(num=num, artist=artist.strip()))\n",
    "            if genius_artist == None:\n",
    "                log(\"{artist} not found\".format(num=num, artist=artist.strip()))\n",
    "                continue\n",
    "                           \n",
    "            artist_data =  process_artist(genius_artist)\n",
    "                           \n",
    "            log(\"{artist} number of songs: {song_num}\".format(num=num, artist=artist.strip(), song_num=len(genius_artist.songs)))\n",
    "            \n",
    "            for song in genius_artist.songs:\n",
    "                song_data = process_song(song)\n",
    "                \n",
    "                # Add to final list\n",
    "                final_.append(build_entry(artist, song.title, song_data))\n",
    "    \n",
    "    except Exception as e:\n",
    "        log(\"Something went wrong: {error}\".format(num=num, error= e))\n",
    "    \n",
    "    \n",
    "def run(multi_core=False): \n",
    "    \n",
    "    # Setup Genius\n",
    "    genius = genius_setup()\n",
    "    \n",
    "    # Load in any previous data\n",
    "    print(\"Reading previous\")\n",
    "    read_csv()\n",
    "    \n",
    "    pool = None\n",
    "    try:  \n",
    "        if multi_core:\n",
    "            # multiprocess.log_to_stderr().setLevel(logging.DEBUG)\n",
    "            print(\"Multiprocessing with {process_number} processes\".format(process_number=process_number))\n",
    "            \n",
    "            artist_queue = multiprocess.Manager().Queue()\n",
    "            get_artists(artist_queue)\n",
    "            \n",
    "            for x in range(process_number):\n",
    "                artist_queue.put(None)\n",
    "            \n",
    "            print(artist_queue.qsize())\n",
    "            # creating processes\n",
    "            with multiprocess.get_context(\"spawn\").Pool(process_number) as pool:\n",
    "                args = [(artist_queue, x, genius, final_) for x in range(process_number)]\n",
    "                pool.map(search_genius, args)\n",
    "                pool.close()\n",
    "                pool.join()\n",
    "            \n",
    "        else:\n",
    "            print(\"Running single core\")\n",
    "            artist_queue = queue.Queue()\n",
    "            get_artists(artist_queue)\n",
    "            artist_queue.put(None)\n",
    "            print(artist_queue.qsize())\n",
    "            search_genius((artist_queue, 0, genius, final_))\n",
    "\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        if pool:\n",
    "            pool.close()\n",
    "            pool.terminate()\n",
    "            pool.join()\n",
    "        print(\"KeyboardInterrupt: Writing results\")\n",
    "    \n",
    "    finally:\n",
    "        write_to_csv(list(final_))                       \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run(multi_core=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genius = genius_setup()\n",
    "# genius_artist = genius.search_artist(\"Sam Hunt\", per_page=50, get_full_info=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genius_artist.songs[30].lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use TensorFlow to generate text embeddings for our lyric data. First we install Tensorflow and the ANNOY (approximate nearest neighbors) library from Spotify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (2.6.2)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (0.15.0)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (0.37.0)\n",
      "Requirement already satisfied: gast==0.4.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: clang~=5.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (5.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (1.42.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: keras<2.7,>=2.6.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.7,>=2.6.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: tensorboard<2.7,>=2.6.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: cached-property in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from h5py~=3.1.0->tensorflow) (1.5.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (1.35.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (59.3.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow) (4.8.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: dataclasses in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from werkzeug>=0.11.15->tensorboard<2.7,>=2.6.0->tensorflow) (0.8)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: tensorflow_hub in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (0.12.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow_hub) (1.19.5)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow_hub) (3.19.1)\n",
      "Requirement already satisfied: annoy in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tensorflow\n",
    "!pip3 install tensorflow_hub\n",
    "!pip3 install annoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/braydenturner/Library/Python/3.8/lib/python/site-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior() \n",
    "# tf.get_logger().setLevel(logging.ERROR)\n",
    "import tensorflow_hub as hub\n",
    "from annoy import AnnoyIndex\n",
    "import pickle\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn import random_projection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we set global variables to store our Annoy index and our universal counter to keep track of lyric entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grab data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define several helper functions to load lyric lines documents, and use Tensorflow to get embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define input path\n",
    "input_file=\"song_data_2.csv\"\n",
    "input_csv_path = os.path.join(os.path.curdir, 'data', input_file)\n",
    "csv.field_size_limit(100000000)\n",
    "\n",
    "\n",
    "def batch_load():\n",
    "    \"\"\"\n",
    "    Load a batch of 1000 songs - not used unless batching input\n",
    "    \"\"\"\n",
    "    \n",
    "    batch_sentences = []\n",
    "    global counter\n",
    "    \n",
    "    print(\"loading batch of songs, starting at song\", counter)\n",
    "    \n",
    "    for x in range(1000):\n",
    "        \n",
    "        document = next(documents)\n",
    "\n",
    "        data = document['data']\n",
    "        lines = data.split(\"|\")\n",
    "\n",
    "        song = document['song']\n",
    "        artist = document['artist']\n",
    "        for line in lines:\n",
    "            ids[counter] = (line, song, artist)\n",
    "            batch_sentences.append(line)\n",
    "            counter += 1\n",
    "        \n",
    "    return batch_sentences\n",
    "\n",
    "\n",
    "def get_lines():\n",
    "    \"\"\"\n",
    "    Get individual lines from the input CSV, to use as the input for embeddings\n",
    "    \"\"\"\n",
    "    songs = []\n",
    "    \n",
    "    with open(input_csv_path, mode ='r+', encoding = 'utf-8') as file:   \n",
    "            datareader = csv.DictReader(file)\n",
    "            next(datareader)\n",
    "            for row in datareader:\n",
    "                data = row['data']\n",
    "                song = row['song']\n",
    "                artist = row['artist']\n",
    "    \n",
    "                songs.append([data, song, artist])\n",
    "                    \n",
    "                # if len(lines) % 100000 == 0:\n",
    "                #     print(\"{} lines added\".format(len(lines)))\n",
    "    \n",
    "    random.shuffle(songs)\n",
    "    lines = []\n",
    "    for x in songs:\n",
    "        data, song, artist = x\n",
    "        lyrics = data.split(\"|\")\n",
    "\n",
    "        for lyric in lyrics:\n",
    "            lines.append([lyric, song, artist])\n",
    "    \n",
    "    del songs\n",
    "    print(\"total lines added: {}\".format(len(lines)))\n",
    "    \n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-07 18:44:27.492506: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-07 18:44:27.493644: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-12-07 18:44:27.494292: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2021-12-07 18:44:27.702024: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# Retrieves the embedding for a batch of sentences \n",
    "\n",
    "vector_length = 64\n",
    "\n",
    "embed_module = hub.Module(\"https://tfhub.dev/google/universal-sentence-encoder/1\")\n",
    "placeholder = tf.placeholder(dtype=tf.string)\n",
    "embed = embed_module(placeholder)\n",
    "session = tf.Session()\n",
    "session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "transformer = random_projection.GaussianRandomProjection(vector_length)\n",
    "\n",
    "def get_embeddings(sentences):\n",
    "    \"\"\"\n",
    "    Gets embeddings for a given line (document)\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Getting embeddings...\")\n",
    "    embeddings = session.run(embed, feed_dict={placeholder: sentences})\n",
    "    \n",
    "    print(\"Reducing dimensionality...\")\n",
    "    reduced_embeddings = transformer.fit_transform(embeddings)\n",
    "    \n",
    "    return reduced_embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Annoy Index\n",
    "Finally we build the index for our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up mapping and counter to keep track of documents\n",
    "counter = 0\n",
    "mapping = {}\n",
    "file_name = \"annoy_index_64_small\"\n",
    "\n",
    "# Initialize the ANNOY index \n",
    "ann = AnnoyIndex(vector_length, metric='angular')\n",
    "\n",
    "def add_items_to_index(batch, embeddings):\n",
    "    \"\"\"\n",
    "    Adds items to an ANNOY index\n",
    "    \n",
    "    sentences: a list of \n",
    "    embeddings: a list of tensorflow embeddings for sentences\n",
    "    \"\"\" \n",
    "    global ann, counter, mapping\n",
    "    \n",
    "    for line, embed in zip(batch, embeddings):\n",
    "        # if counter % batch_size == 0:\n",
    "        #     print(\"added {} items to index\".format(counter+batch_size))\n",
    "            \n",
    "        ann.add_item(counter, embed)\n",
    "        mapping[counter] = line\n",
    "        counter +=1  \n",
    "\n",
    "def build_ann_index(batch_size=200000):\n",
    "    \"\"\"\n",
    "    Constructs the ANNOY index\n",
    "    \"\"\"\n",
    "    print(\"getting lines from CSV file...\")\n",
    "    lines = get_lines()\n",
    "    print(\"lines retrieved, getting embeddings...\")\n",
    "    \n",
    "    # num_lines = 100000 * 10\n",
    "    num_lines = len(lines)\n",
    "    \n",
    "    ann.on_disk_build(file_name)\n",
    "\n",
    "    # get the embeddings in batches - 1/50th of data set to test\n",
    "    # for x in range(0, num_lines, batch_size):\n",
    "    while len(lines) > 0:\n",
    "        \n",
    "        print(\"Operating on lines {} - {}\".format(counter, counter + batch_size))\n",
    "        start = 0\n",
    "        if batch_size >= len(lines):\n",
    "            end = len(lines)\n",
    "        else:\n",
    "            end = batch_size\n",
    "        \n",
    "        batch = lines[start:end]\n",
    "        \n",
    "        lyrics = [x[0] for x in batch]\n",
    "        embeddings = get_embeddings(lyrics)\n",
    "        add_items_to_index(batch, embeddings)\n",
    "        \n",
    "        del embeddings, lyrics\n",
    "        del lines[:end]\n",
    "        \n",
    "        print(\"{} left\".format(len(lines)))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting lines from CSV file...\n",
      "total lines added: 47073023\n",
      "lines retrieved, getting embeddings...\n",
      "Operating on lines 0 - 200000\n",
      "Getting embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-07 18:45:27.665793: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reducing dimensionality...\n",
      "46873023 left\n",
      "Operating on lines 200000 - 400000\n",
      "Getting embeddings...\n",
      "Reducing dimensionality...\n",
      "46673023 left\n",
      "Operating on lines 400000 - 600000\n",
      "Getting embeddings...\n",
      "Reducing dimensionality...\n",
      "46473023 left\n",
      "Operating on lines 600000 - 800000\n",
      "Getting embeddings...\n",
      "Reducing dimensionality...\n",
      "46273023 left\n",
      "Operating on lines 800000 - 1000000\n",
      "Getting embeddings...\n",
      "Reducing dimensionality...\n",
      "46073023 left\n",
      "Operating on lines 1000000 - 1200000\n",
      "Getting embeddings...\n",
      "Reducing dimensionality...\n",
      "45873023 left\n",
      "Operating on lines 1200000 - 1400000\n",
      "Getting embeddings...\n",
      "Reducing dimensionality...\n",
      "45673023 left\n",
      "Operating on lines 1400000 - 1600000\n",
      "Getting embeddings...\n",
      "Reducing dimensionality...\n",
      "45473023 left\n",
      "Operating on lines 1600000 - 1800000\n",
      "Getting embeddings...\n",
      "Reducing dimensionality...\n",
      "45273023 left\n",
      "Operating on lines 1800000 - 2000000\n",
      "Getting embeddings...\n",
      "Reducing dimensionality...\n",
      "45073023 left\n",
      "Operating on lines 2000000 - 2200000\n",
      "Getting embeddings...\n",
      "Reducing dimensionality...\n",
      "44873023 left\n",
      "Operating on lines 2200000 - 2400000\n",
      "Getting embeddings...\n",
      "Reducing dimensionality...\n",
      "44673023 left\n",
      "Operating on lines 2400000 - 2600000\n",
      "Getting embeddings...\n",
      "Reducing dimensionality...\n",
      "44473023 left\n",
      "Operating on lines 2600000 - 2800000\n",
      "Getting embeddings...\n",
      "Reducing dimensionality...\n",
      "44273023 left\n",
      "Operating on lines 2800000 - 3000000\n",
      "Getting embeddings...\n",
      "Reducing dimensionality...\n",
      "44073023 left\n",
      "Operating on lines 3000000 - 3200000\n",
      "Getting embeddings...\n",
      "Reducing dimensionality...\n",
      "43873023 left\n",
      "Operating on lines 3200000 - 3400000\n",
      "Getting embeddings...\n",
      "Reducing dimensionality...\n",
      "43673023 left\n",
      "Operating on lines 3400000 - 3600000\n",
      "Getting embeddings...\n",
      "Reducing dimensionality...\n",
      "43473023 left\n",
      "Operating on lines 3600000 - 3800000\n",
      "Getting embeddings...\n",
      "Reducing dimensionality...\n",
      "43273023 left\n",
      "Operating on lines 3800000 - 4000000\n",
      "Getting embeddings...\n",
      "Reducing dimensionality...\n",
      "43073023 left\n",
      "Operating on lines 4000000 - 4200000\n",
      "Getting embeddings...\n",
      "Reducing dimensionality...\n",
      "42873023 left\n",
      "Operating on lines 4200000 - 4400000\n",
      "Getting embeddings...\n",
      "Reducing dimensionality...\n",
      "42673023 left\n",
      "Operating on lines 4400000 - 4600000\n",
      "Getting embeddings...\n",
      "Reducing dimensionality...\n",
      "42473023 left\n",
      "Operating on lines 4600000 - 4800000\n",
      "Getting embeddings...\n",
      "Reducing dimensionality...\n",
      "42273023 left\n",
      "Operating on lines 4800000 - 5000000\n",
      "Getting embeddings...\n",
      "Reducing dimensionality...\n",
      "42073023 left\n",
      "Operating on lines 5000000 - 5200000\n",
      "Getting embeddings...\n",
      "Reducing dimensionality...\n",
      "41873023 left\n",
      "Operating on lines 5200000 - 5400000\n",
      "Getting embeddings...\n",
      "Reducing dimensionality...\n",
      "41673023 left\n",
      "Operating on lines 5400000 - 5600000\n",
      "Getting embeddings...\n",
      "Reducing dimensionality...\n",
      "41473023 left\n",
      "Operating on lines 5600000 - 5800000\n",
      "Getting embeddings...\n",
      "Reducing dimensionality...\n",
      "41273023 left\n",
      "Operating on lines 5800000 - 6000000\n",
      "Getting embeddings...\n",
      "Reducing dimensionality...\n",
      "41073023 left\n",
      "Operating on lines 6000000 - 6200000\n",
      "Getting embeddings...\n",
      "Reducing dimensionality...\n",
      "40873023 left\n",
      "Operating on lines 6200000 - 6400000\n",
      "Getting embeddings...\n",
      "Reducing dimensionality...\n",
      "40673023 left\n",
      "Operating on lines 6400000 - 6600000\n",
      "Getting embeddings...\n",
      "Reducing dimensionality...\n",
      "40473023 left\n",
      "Operating on lines 6600000 - 6800000\n",
      "Getting embeddings...\n",
      "Reducing dimensionality...\n",
      "40273023 left\n",
      "Operating on lines 6800000 - 7000000\n",
      "Getting embeddings...\n",
      "Reducing dimensionality...\n",
      "40073023 left\n",
      "Operating on lines 7000000 - 7200000\n",
      "Getting embeddings...\n",
      "Reducing dimensionality...\n",
      "39873023 left\n",
      "Operating on lines 7200000 - 7400000\n",
      "Getting embeddings...\n",
      "Reducing dimensionality...\n",
      "39673023 left\n",
      "Operating on lines 7400000 - 7600000\n",
      "Getting embeddings...\n",
      "Reducing dimensionality...\n",
      "39473023 left\n",
      "Operating on lines 7600000 - 7800000\n",
      "Getting embeddings...\n",
      "Reducing dimensionality...\n",
      "39273023 left\n",
      "Operating on lines 7800000 - 8000000\n",
      "Getting embeddings...\n",
      "KeyboardInterrupt\n",
      "Building index...\n",
      "mapping saved\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    build_ann_index()\n",
    "except KeyboardInterrupt:\n",
    "    print(\"KeyboardInterrupt\")\n",
    "finally:\n",
    "    print(\"Building index...\")\n",
    "    ann.build(100)\n",
    "    ann.unload()\n",
    "    \n",
    "    with open(file_name + '.mapping', 'wb') as handle:\n",
    "        pickle.dump(mapping, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    print('mapping saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annoy index loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "prefault is set to true, but MAP_POPULATE is not defined on this platform"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping file loaded.\n"
     ]
    }
   ],
   "source": [
    "ann = AnnoyIndex(vector_length, metric='angular')\n",
    "ann.load(\"annoy_index_small\", prefault=True)\n",
    "print('annoy index loaded.')\n",
    "with open('annoy_index_small.mapping', 'rb') as handle:\n",
    "    mapping = pickle.load(handle)\n",
    "print('mapping file loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, use a sample query to test the performance of our retreival system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting query embeddings\n",
      "getting nearest neighbors\n",
      "Closest: \n",
      "1. Keep on Shinin’ -  Future :\n",
      "     I'm turnin' up  you go to sleep     \n",
      "     I whipped me up that V12     \n",
      "     I pull up in that V12     \n",
      "==== I got a hundred bands in my email ====\n",
      "     I'm on the yacht  no sea shells     \n",
      "     On tough sand I touch bands     \n",
      "\n",
      "\n",
      "2. Boost Mobile (Freestyle) -  Young Roddy :\n",
      "     Alright  let me stop fuckin' around  hold this down for my set     \n",
      "     Jet Life  ever since Route The Ruler  they been calling me the truth     \n",
      "     I use to have a hooptie  til Spitta loaned me his coupe     \n",
      "==== I finally got an iPhone  use to be team boost ====\n",
      "     But it made me hella money  boy my shoe box the proof     \n",
      "     I grew up in the hood where nigga's reppin' soowoop     \n",
      "\n",
      "\n",
      "3. Funkmaster Flex Freestyle (2012) -  Meek Mill :\n",
      "     Got a couple of Rovers  had a drop one Mercedes     \n",
      "     I know these suckers don’t like me  I'm probably poppin' they lady     \n",
      "     I got 100 racks on me now     \n",
      "==== No computer but I got a MAC on me now ====\n",
      "     And I'm a shooter and I really clap homie now     \n",
      "     And fuck the jail 'cause my nigga Ross hold me down     \n",
      "\n",
      "\n",
      "4. I Hope U Get This Kite -  E-40 :\n",
      "     I see you when you touch down (touch down)     \n",
      "     I see you when you come home  hold on (hold on)     \n",
      "     To all of my fellas up in jail that's in there gettin swell     \n",
      "==== That ordered my music  bought my music through music-by-mail ====\n",
      "     We still out here doin it  we ridin Buick LeSabres     \n",
      "     And puttin dubs on them bitches  they callin 'em scrapers     \n",
      "\n",
      "\n",
      "5. Trap N Roll -  Wyclef Jean :\n",
      "     Stick together like dread locks     \n",
      "     Keep the doors up     \n",
      "     Waka Flocka  that's hip-hop     \n",
      "==== I'm up here and make a phone in the m box ====\n",
      "     My mama base but I ain't have a boat     \n",
      "     If I ain't have a name just splittin pain     \n",
      "\n",
      "\n",
      "6. I Phones -  Young Pappy :\n",
      "     “I got 650 ”     \n",
      "     “Nigga  I need seven”     \n",
      "     “Come on  bro  work with me!”     \n",
      "==== “Alright  send the Western Union  send the beat to the e-mail! ====\n",
      "     And send it to Yahoo  I don’t give out my Gmail!”     \n",
      "     You don’t motherfucking know me from the old me     \n",
      "\n",
      "\n",
      "7. What War Is All About -  Conejo :\n",
      "     I'm the first  to let them fly     \n",
      "     What you mean you the first to fucken die     \n",
      "     I pay the block     \n",
      "==== I got the codes encrypted ====\n",
      "     At the stove in the kitchen     \n",
      "     Getting ready to whip it     \n",
      "\n",
      "\n",
      "8. Master Peewee -  Peewee Longway :\n",
      "     It's the ice cream man     \n",
      "          \n",
      "     Whip up that yellow  Yo Gotti  that white peter pan     \n",
      "==== Jugg the bricks off a flip phone Virgin Mobile ====\n",
      "     Zone 1  Zone 6 Mr. Ice Cream Mobile     \n",
      "     Youngin thuggin in the trenches like Hot Boy Turk     \n",
      "\n",
      "\n",
      "9. Rrring -  Charli XCX :\n",
      "     Motorola-rola  roll up  yeah     \n",
      "     Motorola-rola  roll up     \n",
      "     Motorola-rola  roll up  yeah     \n",
      "==== Motorola  roll up  roll up ====\n",
      "     Yeah  yeah (do it  do it)     \n",
      "          \n",
      "\n",
      "\n",
      "10. Rrring -  Charli XCX :\n",
      "     Motorola-rola  roll up  yeah     \n",
      "     Motorola-rola  roll up     \n",
      "     Motorola-rola  roll up  yeah     \n",
      "==== Motorola  roll up  roll up ====\n",
      "     Yeah  yeah (do it  do it)     \n",
      "          \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_sentence = \"Getting an email on my iPhone\"\n",
    "\n",
    "query_embeddings = get_embeddings([input_sentence])[0]\n",
    "print(\"getting query embeddings\")\n",
    "\n",
    "# Return 10 nearest neighbors\n",
    "print(\"getting nearest neighbors\")\n",
    "nns = ann.get_nns_by_vector(query_embeddings, 10, include_distances=False)\n",
    "\n",
    "print(\"Closest: \")\n",
    "for idx, item in enumerate(nns):\n",
    "    print(\"{}. {} - {}:\".format(idx+1, mapping[item][1], mapping[item][2]))\n",
    "    for x in range(item-3, item+3):\n",
    "        if x == item:\n",
    "            print(\"==== {} ====\".format(mapping[x][0]))\n",
    "        else:\n",
    "            print(\"     {}     \".format(mapping[x][0]))\n",
    "    \n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need ipywidgets to display interactive widgets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (7.6.5)\n",
      "Requirement already satisfied: ipython>=4.0.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from ipywidgets) (7.16.1)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from ipywidgets) (5.1.3)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from ipywidgets) (1.0.2)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from ipywidgets) (3.5.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from ipywidgets) (4.3.3)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from ipywidgets) (5.5.6)\n",
      "Requirement already satisfied: jupyter-client in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\n",
      "Requirement already satisfied: tornado>=4.2 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.4.4)\n",
      "Requirement already satisfied: backcall in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: jedi>=0.10 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.18.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (3.0.3)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (59.3.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (5.1.0)\n",
      "Requirement already satisfied: pygments in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (2.10.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets) (3.2.0)\n",
      "Requirement already satisfied: jupyter-core in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets) (4.9.1)\n",
      "Requirement already satisfied: six in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from traitlets>=4.3.1->ipywidgets) (1.15.0)\n",
      "Requirement already satisfied: notebook>=4.4.1 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from widgetsnbextension~=3.5.0->ipywidgets) (6.4.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from jedi>=0.10->ipython>=4.0.0->ipywidgets) (0.8.2)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (0.18.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (21.2.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (4.8.2)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (6.0.7)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.8.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.12.1)\n",
      "Requirement already satisfied: pyzmq>=17 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (22.3.0)\n",
      "Requirement already satisfied: prometheus-client in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.12.0)\n",
      "Requirement already satisfied: argon2-cffi in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.1.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from jupyter-core->nbformat>=4.2.0->ipywidgets) (302)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: pywinpty>=1.1.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from terminado>=0.8.3->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.1.5)\n",
      "Requirement already satisfied: cffi>=1.0.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.15.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from importlib-metadata->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from importlib-metadata->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: bleach in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (4.1.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.3)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: testpath in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.21)\n",
      "Requirement already satisfied: async-generator in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.10)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.2)\n",
      "Requirement already satisfied: webencodings in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: pyparsing<3,>=2.0.2 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we set up our widgets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0205bd3c99ae4c4a8be127bdb1de448b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "TwoByTwoLayout(children=(Text(value='Sitting in my truck', description='Input query:', layout=Layout(grid_area…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "query = widgets.Text(\n",
    "        value='Sitting in my truck',\n",
    "        description='Input query:')\n",
    "\n",
    "button = widgets.Button(description='Submit')\n",
    "\n",
    "slider = widgets.IntSlider(\n",
    "         value=5,\n",
    "         min=0,\n",
    "         max=20,\n",
    "         step=1,\n",
    "         description='# of results:')\n",
    "\n",
    "def on_click(_):\n",
    "    with query:\n",
    "        clear_output()\n",
    "        print(query.value)\n",
    "        \n",
    "\n",
    "interact = widgets.TwoByTwoLayout(top_left=query,\n",
    "                       bottom_left=slider)\n",
    "\n",
    "interact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we run the query defined above, looking for the number of results requested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running query...\n",
      "Top 5 results for 'guy in a truck'\n",
      "1. My Neck Of The Woods -  Blake Shelton :\n",
      "     Or pouring rain     \n",
      "     Sells tomatoes     \n",
      "     From the back     \n",
      "==== Of his pickup truck ====\n",
      "     Reads the Bible line for line     \n",
      "     While sipping on     \n",
      "\n",
      "\n",
      "2. Like You Were Mine -  Jason Aldean :\n",
      "     Still feeling you like you never said goodbye     \n",
      "     Like you were mine     \n",
      "          \n",
      "==== Sometimes this take-me-back truck ====\n",
      "     Talks me into burning gas     \n",
      "     Past your house     \n",
      "\n",
      "\n",
      "3. Cop Car -  Sam Hunt :\n",
      "     We thought we had all night     \n",
      "     There was no need to rush     \n",
      "     That's when those cops     \n",
      "==== Came pulling up ====\n",
      "     And I thought     \n",
      "     Man  ain't this some shhhh     \n",
      "\n",
      "\n",
      "4. Cop Car (Acoustic) -  Sam Hunt :\n",
      "     We thought we had all night     \n",
      "     There  was no need to rush     \n",
      "     That's  when those cops     \n",
      "==== Came pulling up ====\n",
      "     And  I thought     \n",
      "     Man  ain't this some shhhh     \n",
      "\n",
      "\n",
      "5. Meija -  Porno for Pyros :\n",
      "     Everybody  count your money!     \n",
      "     Everybody  yeah  you better count your money!     \n",
      "     Where you going  Meija?     \n",
      "==== Took the car ====\n",
      "     Out for a drive     \n",
      "     Didn't come back     \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# code autoruns, not sure how to get it to wait for a user input\n",
    "\n",
    "user_query = query.value\n",
    "print(\"running query...\")\n",
    "\n",
    "query_embeddings = get_embeddings([user_query])[0]\n",
    "\n",
    "# Return X nearest neighbors\n",
    "nns = ann.get_nns_by_vector(query_embeddings, slider.value, include_distances=False)\n",
    "\n",
    "print(\"Top {} results for \\'{}\\'\".format(slider.value, query.value))\n",
    "for idx, item in enumerate(nns):\n",
    "    print(\"{}. {} - {}:\".format(idx+1, mapping[item][1], mapping[item][2]))\n",
    "    for x in range(item-3, item+3):\n",
    "        if x == item:\n",
    "            print(\"==== {} ====\".format(mapping[x][0]))\n",
    "        else:\n",
    "            print(\"     {}     \".format(mapping[x][0]))\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CS410 Project Bae Area",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
