{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DlrmluRfNayp"
   },
   "source": [
    "First, we install the lyricsgenius API, as well as multiprocess to increase speed of data scraping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2v6oNAIxM1TN",
    "outputId": "0912025a-a0ea-47e6-8445-0e0c3cb6360c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: multiprocess in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (0.70.12.2)\n",
      "Requirement already satisfied: dill>=0.3.4 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from multiprocess) (0.3.4)\n",
      "Requirement already satisfied: lyricsgenius in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: requests>=2.20.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from lyricsgenius) (2.26.0)\n",
      "Requirement already satisfied: beautifulsoup4>=4.6.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from lyricsgenius) (4.10.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from beautifulsoup4>=4.6.0->lyricsgenius) (2.3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from requests>=2.20.0->lyricsgenius) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from requests>=2.20.0->lyricsgenius) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from requests>=2.20.0->lyricsgenius) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from requests>=2.20.0->lyricsgenius) (3.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install multiprocess\n",
    "!pip install lyricsgenius"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the libraries and set a path for our input file of artists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "AwPBO5kVbh-h"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import multiprocess\n",
    "import queue\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "from requests.exceptions import HTTPError, ConnectionError, RequestException\n",
    "from lyricsgenius import Genius\n",
    "\n",
    "\n",
    "# OS agnostic\n",
    "import os \n",
    "CSV_PATH = os.path.join(os.path.curdir, 'artists', '10000-MTV-Music-Artists-page-%s.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PjAsUT5ZOSex"
   },
   "source": [
    "# Scrape Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set up a lyricsgenius token, and use the API to pull the lyrics data for each artist in the dataset for the top 10,000 artists from MTV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "7zBQzXBJNabo"
   },
   "outputs": [],
   "source": [
    "# Genius setup\n",
    "             \n",
    "def genius_setup():\n",
    "    token = \"EBufquOcw_ts4Y4V7yiddUNyUakTdqCpnMZhiI3XtAScWOntEom8Hj4T87gAV_cA\"\n",
    "    genius = Genius(token, retries=2)\n",
    "\n",
    "    genius.verbose = False\n",
    "    genius.remove_section_headers = True\n",
    "    genius.skip_non_songs = True\n",
    "    genius.excluded_terms = [\"(Remix)\", \"(Live)\"]\n",
    "\n",
    "    return genius    \n",
    "\n",
    "\n",
    "# Multiprocessing cores\n",
    "process_number = int(multiprocess.cpu_count()) * 2\n",
    "\n",
    "# Data management\n",
    "final_ = multiprocess.Manager().list()\n",
    "\n",
    "# artist_queue = queue.Queue()\n",
    "# final_ = []\n",
    "checked_artists = set()\n",
    "\n",
    "file_name = \"song_data_2.csv\"\n",
    "\n",
    "\n",
    "# Pull out artists\n",
    "def get_artists(queue):\n",
    "    for x in range(1,5):\n",
    "        path = CSV_PATH % str(x)\n",
    "        with open(path, encoding=\"UTF-8\") as csvfile:\n",
    "            TopArtists = csv.reader(csvfile)\n",
    "            \n",
    "            # Skip header\n",
    "            next(TopArtists)\n",
    "            for row in TopArtists:\n",
    "                artist = row[0]\n",
    "                # Check if we should skip this artists since we already found the data\n",
    "                if artist not in checked_artists:\n",
    "                    queue.put(artist)\n",
    "\n",
    "\n",
    "# File management\n",
    "def write_to_csv(data):\n",
    "    \"\"\"\n",
    "    data: list of dictionaries {artist, song, data}\n",
    "    \"\"\"\n",
    "    global file_name\n",
    "    \n",
    "    csv_path = os.path.join(os.path.curdir, 'data', file_name)\n",
    "    with open(csv_path, 'w') as csv_file: \n",
    "        # creating a csv dict writer object \n",
    "        print(\"Entries: {num}\".format(num=len(data)))\n",
    "        keys = data[0].keys()\n",
    "        writer = csv.DictWriter(csv_file, fieldnames = keys) \n",
    "        \n",
    "        # writing headers (field names) \n",
    "        writer.writeheader() \n",
    "        \n",
    "        # writing data rows \n",
    "        writer.writerows(data) \n",
    "        \n",
    "\n",
    "def read_csv():\n",
    "    global final_, checked_artists, file_name   \n",
    "    \n",
    "    csv_path = os.path.join(os.path.curdir, 'data', file_name)\n",
    "    \n",
    "    # opening the CSV file\n",
    "    try:\n",
    "        with open(csv_path, mode ='r', encoding=\"UTF-8\") as file:   \n",
    "\n",
    "            # reading the CSV file\n",
    "            data = csv.DictReader(file)\n",
    "\n",
    "            for entry in data:\n",
    "                checked_artists.add(entry[\"artist\"])\n",
    "                final_.append(entry)\n",
    "                \n",
    "        print(\"Number of artists already found {num}\".format(num=len(checked_artists)))\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    \n",
    "\n",
    "# Run genius search\n",
    "def search_genius(args):\n",
    "    import sys\n",
    "    from requests.exceptions import RequestException\n",
    "    artist_queue, num, genius, final_ = args\n",
    "    \n",
    "    def log(string):\n",
    "        print(\"[{num}] \".format(num=num) + string + \"\\n\", end='')\n",
    "        sys.stdout.flush()\n",
    "    \n",
    "    # Processing\n",
    "    def clean_data(data):\n",
    "        cleaned_data = data.replace(\"\\n\", \"|\").replace(\",\", \" \")\n",
    "        return cleaned_data\n",
    "\n",
    "    def process_artist(artist):\n",
    "        artist_dict = artist.to_dict()\n",
    "        return \"\"\n",
    "\n",
    "    def process_song(song):\n",
    "        lyrics = clean_data(song.lyrics)\n",
    "        return lyrics\n",
    "\n",
    "    def build_entry(artist, song, data, columns = [\"artist\", \"song\", \"data\"]):\n",
    "        entry = {\"artist\": artist, \"song\": song, \"data\": data}\n",
    "        return entry\n",
    "    \n",
    "    log(\"Starting\")\n",
    "    try:\n",
    "        while True:\n",
    "            genius_artist = None\n",
    "            artist = artist_queue.get()\n",
    "            if artist is None:\n",
    "                log(\"Done\")\n",
    "                return\n",
    "            log(\"Remaining: [{queue}]. Searching {artist}\".format(queue=artist_queue.qsize(), artist=artist.strip()))\n",
    "            \n",
    "            # Pull data for artist from genius\n",
    "            for x in range(5):\n",
    "                try:\n",
    "                    genius_artist = genius.search_artist(artist, per_page=50, get_full_info=False)\n",
    "                    break\n",
    "                except RequestException as e:\n",
    "                    log(\"HTTPSConnectionPool exception. Attempt {}/5\".format(x+1))\n",
    "                except Exception as e:\n",
    "                    log(\"Exception. Attempt {}/3\".format(x+1))\n",
    "            \n",
    "            log(\"Finished {artist}\".format(num=num, artist=artist.strip()))\n",
    "            if genius_artist == None:\n",
    "                log(\"{artist} not found\".format(num=num, artist=artist.strip()))\n",
    "                continue\n",
    "                           \n",
    "            artist_data =  process_artist(genius_artist)\n",
    "                           \n",
    "            log(\"{artist} number of songs: {song_num}\".format(num=num, artist=artist.strip(), song_num=len(genius_artist.songs)))\n",
    "            \n",
    "            for song in genius_artist.songs:\n",
    "                song_data = process_song(song)\n",
    "                \n",
    "                # Add to final list\n",
    "                final_.append(build_entry(artist, song.title, song_data))\n",
    "    \n",
    "    except Exception as e:\n",
    "        log(\"Something went wrong: {error}\".format(num=num, error= e))\n",
    "    \n",
    "    \n",
    "def run(multi_core=False): \n",
    "    \n",
    "    # Setup Genius\n",
    "    genius = genius_setup()\n",
    "    \n",
    "    # Load in any previous data\n",
    "    print(\"Reading previous\")\n",
    "    read_csv()\n",
    "    \n",
    "    pool = None\n",
    "    try:  \n",
    "        if multi_core:\n",
    "            # multiprocess.log_to_stderr().setLevel(logging.DEBUG)\n",
    "            print(\"Multiprocessing with {process_number} processes\".format(process_number=process_number))\n",
    "            \n",
    "            artist_queue = multiprocess.Manager().Queue()\n",
    "            get_artists(artist_queue)\n",
    "            \n",
    "            for x in range(process_number):\n",
    "                artist_queue.put(None)\n",
    "            \n",
    "            print(artist_queue.qsize())\n",
    "            # creating processes\n",
    "            with multiprocess.get_context(\"spawn\").Pool(process_number) as pool:\n",
    "                args = [(artist_queue, x, genius, final_) for x in range(process_number)]\n",
    "                pool.map(search_genius, args)\n",
    "                pool.close()\n",
    "                pool.join()\n",
    "            \n",
    "        else:\n",
    "            print(\"Running single core\")\n",
    "            artist_queue = queue.Queue()\n",
    "            get_artists(artist_queue)\n",
    "            artist_queue.put(None)\n",
    "            print(artist_queue.qsize())\n",
    "            search_genius((artist_queue, 0, genius, final_))\n",
    "\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        if pool:\n",
    "            pool.close()\n",
    "            pool.terminate()\n",
    "            pool.join()\n",
    "        print(\"KeyboardInterrupt: Writing results\")\n",
    "    \n",
    "    finally:\n",
    "        write_to_csv(list(final_))                       \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run(multi_core=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genius = genius_setup()\n",
    "# genius_artist = genius.search_artist(\"Sam Hunt\", per_page=50, get_full_info=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genius_artist.songs[30].lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use TensorFlow to generate text embeddings for our lyric data. First we install Tensorflow and the ANNOY (approximate nearest neighbors) library from Spotify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (2.6.2)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (0.15.0)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (0.37.0)\n",
      "Requirement already satisfied: gast==0.4.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: clang~=5.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (5.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (1.42.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: keras<2.7,>=2.6.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.7,>=2.6.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: tensorboard<2.7,>=2.6.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: cached-property in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from h5py~=3.1.0->tensorflow) (1.5.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (1.35.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (59.3.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow) (4.8.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: dataclasses in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from werkzeug>=0.11.15->tensorboard<2.7,>=2.6.0->tensorflow) (0.8)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: tensorflow_hub in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (0.12.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow_hub) (1.19.5)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow_hub) (3.19.1)\n",
      "Requirement already satisfied: annoy in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tensorflow\n",
    "!pip3 install tensorflow_hub\n",
    "!pip3 install annoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/braydenturner/Library/Python/3.8/lib/python/site-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior() \n",
    "# tf.get_logger().setLevel(logging.ERROR)\n",
    "import tensorflow_hub as hub\n",
    "from annoy import AnnoyIndex\n",
    "import pickle\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we set global variables to store our Annoy index and our universal counter to keep track of lyric entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grab data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define several helper functions to load lyric lines documents, and use Tensorflow to get embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define input path\n",
    "input_file=\"song_data_2.csv\"\n",
    "input_csv_path = os.path.join(os.path.curdir, 'data', input_file)\n",
    "csv.field_size_limit(100000000)\n",
    "\n",
    "\n",
    "def batch_load():\n",
    "    \"\"\"\n",
    "    Load a batch of 1000 songs - not used unless batching input\n",
    "    \"\"\"\n",
    "    \n",
    "    batch_sentences = []\n",
    "    global counter\n",
    "    \n",
    "    print(\"loading batch of songs, starting at song\", counter)\n",
    "    \n",
    "    for x in range(1000):\n",
    "        \n",
    "        document = next(documents)\n",
    "\n",
    "        data = document['data']\n",
    "        lines = data.split(\"|\")\n",
    "\n",
    "        song = document['song']\n",
    "        artist = document['artist']\n",
    "        for line in lines:\n",
    "            ids[counter] = (line, song, artist)\n",
    "            batch_sentences.append(line)\n",
    "            counter += 1\n",
    "        \n",
    "    return batch_sentences\n",
    "\n",
    "\n",
    "def get_lines():\n",
    "    \"\"\"\n",
    "    Get individual lines from the input CSV, to use as the input for embeddings\n",
    "    \"\"\"\n",
    "    songs = []\n",
    "    \n",
    "    with open(input_csv_path, mode ='r+', encoding = 'utf-8') as file:   \n",
    "            datareader = csv.DictReader(file)\n",
    "            next(datareader)\n",
    "            for row in datareader:\n",
    "                data = row['data']\n",
    "                song = row['song']\n",
    "                artist = row['artist']\n",
    "    \n",
    "                songs.append([data, song, artist])\n",
    "                    \n",
    "                # if len(lines) % 100000 == 0:\n",
    "                #     print(\"{} lines added\".format(len(lines)))\n",
    "    \n",
    "    random.shuffle(songs)\n",
    "    lines = []\n",
    "    for x in songs:\n",
    "        data, song, artist = x\n",
    "        lyrics = data.split(\"|\")\n",
    "\n",
    "        for lyric in lyrics:\n",
    "            lines.append([lyric, song, artist])\n",
    "    \n",
    "    del songs\n",
    "    print(\"total lines added: {}\".format(len(lines)))\n",
    "    \n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-07 15:40:13.767337: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-07 15:40:13.768471: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-12-07 15:40:13.769332: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2021-12-07 15:40:13.984952: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# Retrieves the embedding for a batch of sentences \n",
    "\n",
    "embed_module = hub.Module(\"https://tfhub.dev/google/universal-sentence-encoder/1\")\n",
    "placeholder = tf.placeholder(dtype=tf.string)\n",
    "embed = embed_module(placeholder)\n",
    "session = tf.Session()\n",
    "session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "\n",
    "def get_embeddings(sentences):\n",
    "    \"\"\"\n",
    "    Gets embeddings for a given line (document)\n",
    "    \"\"\"\n",
    "    \n",
    "    embeddings = session.run(embed, feed_dict={placeholder: sentences})\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Annoy Index\n",
    "Finally we build the index for our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up mapping and counter to keep track of documents\n",
    "counter = 0\n",
    "mapping = {}\n",
    "\n",
    "# Initialize the ANNOY index \n",
    "ann = AnnoyIndex(512, metric='angular')\n",
    "\n",
    "def add_items_to_index(batch, embeddings):\n",
    "    \"\"\"\n",
    "    Adds items to an ANNOY index\n",
    "    \n",
    "    sentences: a list of \n",
    "    embeddings: a list of tensorflow embeddings for sentences\n",
    "    \"\"\" \n",
    "    global ann, counter, mapping\n",
    "    \n",
    "    for line, embed in zip(batch, embeddings):\n",
    "        # if counter % batch_size == 0:\n",
    "        #     print(\"added {} items to index\".format(counter+batch_size))\n",
    "            \n",
    "        ann.add_item(counter, embed)\n",
    "        mapping[counter] = line\n",
    "        counter +=1  \n",
    "\n",
    "def build_ann_index(batch_size=100000):\n",
    "    \"\"\"\n",
    "    Constructs the ANNOY index\n",
    "    \"\"\"\n",
    "    print(\"getting lines from CSV file...\")\n",
    "    lines = get_lines()\n",
    "    print(\"lines retrieved, getting embeddings...\")\n",
    "    \n",
    "    # num_lines = 100000 * 10\n",
    "    num_lines = len(lines)\n",
    "    \n",
    "    ann.on_disk_build(\"annoy_index\")\n",
    "\n",
    "    # get the embeddings in batches - 1/50th of data set to test\n",
    "    # for x in range(0, num_lines, batch_size):\n",
    "    while len(lines) > 0:\n",
    "        \n",
    "        print(\"getting embeddings for lines {} - {}\".format(counter, counter + batch_size))\n",
    "        start = 0\n",
    "        if x + batch_size >= len(lyrics):\n",
    "            end = len(lyrics)\n",
    "        else:\n",
    "            end = batch_size\n",
    "        \n",
    "        batch = lines[start:end]\n",
    "        \n",
    "        lyrics = [x[0] for x in batch]\n",
    "        embeddings = get_embeddings(lyrics)\n",
    "        add_items_to_index(batch, embeddings)\n",
    "        \n",
    "        del embeddings, lyrics\n",
    "        del lines[:end]\n",
    "        \n",
    "        print(\"{} left\".format(len(lines)))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting lines from CSV file...\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    build_ann_index(batch_size=200000)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"KeyboardInterrupt\")\n",
    "finally:\n",
    "    print(\"Building index...\")\n",
    "    ann.build(20)\n",
    "    ann.unload()\n",
    "    \n",
    "    with open('annoy_index.mapping', 'wb') as handle:\n",
    "        pickle.dump(mapping, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    print('mapping saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis = [1, 2, 3 ,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "del lis[2:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 4]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annoy index loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "prefault is set to true, but MAP_POPULATE is not defined on this platform"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping file loaded.\n"
     ]
    }
   ],
   "source": [
    "ann = AnnoyIndex(512, metric='angular')\n",
    "ann.load(\"annoy_index\", prefault=True)\n",
    "print('annoy index loaded.')\n",
    "with open('annoy_index.mapping', 'rb') as handle:\n",
    "    mapping = pickle.load(handle)\n",
    "print('mapping file loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, use a sample query to test the performance of our retreival system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting query embeddings\n",
      "getting nearest neighbors\n",
      "Closest: \n",
      "1. Waitin’ on 5 -  Chris Janson :\n",
      "     If you wanting overtime  well sorry I'm sick     \n",
      "     Waitin' on five to start on six     \n",
      "          \n",
      "==== Everybody watching that tick tock tick ====\n",
      "     Slower it goes the closer it gets     \n",
      "     We'll be cracking and popping and giving it a twist     \n",
      "\n",
      "\n",
      "2. Somebody New (Unreleased) -  Demi Lovato :\n",
      "     But if you're coming to the show     \n",
      "     There's something you should know     \n",
      "          \n",
      "==== I got somebody new ====\n",
      "     I look at him the way I used to     \n",
      "     Look at you     \n",
      "\n",
      "\n",
      "3. Song Covers -  Ellie Goulding :\n",
      "     \"Life Round Here\" - James Blake     \n",
      "     \"Mirrors\" - Justin Timberlake     \n",
      "     \"Only Girl In The World\" - Rihanna     \n",
      "==== \"Roscoe\" - Midlake ====\n",
      "     \"Some Nights\" - Fun     \n",
      "     \"Sweet Disposition\" - The Temper Trap     \n",
      "\n",
      "\n",
      "4. We Carry On -  Tim McGraw :\n",
      "     Just twelve weeks along and she's got a life inside     \n",
      "     Says she's never ever felt so alone     \n",
      "     She walks in the shelter  they say \"welcome home\"     \n",
      "====  ====\n",
      "     And we carry on     \n",
      "     When our lives come undone     \n",
      "\n",
      "\n",
      "5. Unreleased Songs [Discography List] -  Fifth Harmony :\n",
      "     Anything Could Happen     \n",
      "          \n",
      "     B     \n",
      "==== Big Bad Wolf ====\n",
      "     Bitchology     \n",
      "     C     \n",
      "\n",
      "\n",
      "6. The 7/27 Tour Setlist -  Fifth Harmony :\n",
      "     \"We Know\"     \n",
      "     \"Dope\"     \n",
      "     \"Squeeze\"     \n",
      "==== \"Big Bad Wolf\" ====\n",
      "     \"Boss\"     \n",
      "     \"Work from Home\"     \n",
      "\n",
      "\n",
      "7. Language -  Tori Kelly :\n",
      "     So you can learn we need to     \n",
      "          \n",
      "     Lord knows I need patience  mmm     \n",
      "==== Just wanna learn your language ====\n",
      "     Just wanna love you  so what?     \n",
      "     It's gonna be worth it when It's over     \n",
      "\n",
      "\n",
      "8. What Love Is That Way -  Keith Urban :\n",
      "     Just wasn't meant to be     \n",
      "     But somewhere down deep  I still believe     \n",
      "     That we wereEmbedShare URLCopyEmbedCopy     \n",
      "==== You come here lookin' for sympathy ====\n",
      "     Cause it's not everything you thought it would be     \n",
      "     Don't waste your time     \n",
      "\n",
      "\n",
      "9. That’s My Shhh -  Jason Derulo :\n",
      "     One  like a teacher  you're sending me to the corner (woo)     \n",
      "     Two  grabbing and biting while I'm an all on ya     \n",
      "     Three  that's my shit  that's my shit  that's my shit     \n",
      "==== Three  that's my shit  that's my shit  that's my shit ====\n",
      "     One  I can feel it coming down     \n",
      "     Two  grabbing on your head  turn the thing around     \n",
      "\n",
      "\n",
      "10. Algebra -  Jason Derulo :\n",
      "     Ain't with the waitin'  what's my motivation?     \n",
      "     The road less traveled is the one that I'll be takin'     \n",
      "     Lonely days  were the only days     \n",
      "==== I remember the days I would say ====\n",
      "     I could be star tomorrow if I really wanted to     \n",
      "     I could be a star tomorrow if I just get rid of you     \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-07 10:54:27.640021: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "input_sentence = \"black dog\"\n",
    "\n",
    "query_embeddings = get_embeddings([input_sentence])[0]\n",
    "print(\"getting query embeddings\")\n",
    "\n",
    "# Return 10 nearest neighbors\n",
    "print(\"getting nearest neighbors\")\n",
    "nns = ann.get_nns_by_vector(query_embeddings, 10, include_distances=False)\n",
    "\n",
    "print(\"Closest: \")\n",
    "for idx, item in enumerate(nns):\n",
    "    print(\"{}. {} - {}:\".format(idx+1, mapping[item][1], mapping[item][2]))\n",
    "    for x in range(item-3, item+3):\n",
    "        if x == item:\n",
    "            print(\"==== {} ====\".format(mapping[x][0]))\n",
    "        else:\n",
    "            print(\"     {}     \".format(mapping[x][0]))\n",
    "    \n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need ipywidgets to display interactive widgets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (7.6.5)\n",
      "Requirement already satisfied: ipython>=4.0.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from ipywidgets) (7.16.1)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from ipywidgets) (5.1.3)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from ipywidgets) (1.0.2)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from ipywidgets) (3.5.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from ipywidgets) (4.3.3)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from ipywidgets) (5.5.6)\n",
      "Requirement already satisfied: jupyter-client in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\n",
      "Requirement already satisfied: tornado>=4.2 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.4.4)\n",
      "Requirement already satisfied: backcall in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: jedi>=0.10 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.18.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (3.0.3)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (59.3.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (5.1.0)\n",
      "Requirement already satisfied: pygments in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (2.10.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets) (3.2.0)\n",
      "Requirement already satisfied: jupyter-core in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets) (4.9.1)\n",
      "Requirement already satisfied: six in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from traitlets>=4.3.1->ipywidgets) (1.15.0)\n",
      "Requirement already satisfied: notebook>=4.4.1 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from widgetsnbextension~=3.5.0->ipywidgets) (6.4.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from jedi>=0.10->ipython>=4.0.0->ipywidgets) (0.8.2)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (0.18.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (21.2.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (4.8.2)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (6.0.7)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.8.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.12.1)\n",
      "Requirement already satisfied: pyzmq>=17 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (22.3.0)\n",
      "Requirement already satisfied: prometheus-client in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.12.0)\n",
      "Requirement already satisfied: argon2-cffi in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.1.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from jupyter-core->nbformat>=4.2.0->ipywidgets) (302)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: pywinpty>=1.1.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from terminado>=0.8.3->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.1.5)\n",
      "Requirement already satisfied: cffi>=1.0.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.15.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from importlib-metadata->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from importlib-metadata->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: bleach in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (4.1.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.3)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: testpath in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.21)\n",
      "Requirement already satisfied: async-generator in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.10)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.2)\n",
      "Requirement already satisfied: webencodings in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: pyparsing<3,>=2.0.2 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we set up our widgets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0205bd3c99ae4c4a8be127bdb1de448b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "TwoByTwoLayout(children=(Text(value='Sitting in my truck', description='Input query:', layout=Layout(grid_area…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "query = widgets.Text(\n",
    "        value='Sitting in my truck',\n",
    "        description='Input query:')\n",
    "\n",
    "button = widgets.Button(description='Submit')\n",
    "\n",
    "slider = widgets.IntSlider(\n",
    "         value=5,\n",
    "         min=0,\n",
    "         max=20,\n",
    "         step=1,\n",
    "         description='# of results:')\n",
    "\n",
    "def on_click(_):\n",
    "    with query:\n",
    "        clear_output()\n",
    "        print(query.value)\n",
    "        \n",
    "\n",
    "interact = widgets.TwoByTwoLayout(top_left=query,\n",
    "                       bottom_left=slider)\n",
    "\n",
    "interact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we run the query defined above, looking for the number of results requested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running query...\n",
      "Top 5 results for 'guy in a truck'\n",
      "1. My Neck Of The Woods -  Blake Shelton :\n",
      "     Or pouring rain     \n",
      "     Sells tomatoes     \n",
      "     From the back     \n",
      "==== Of his pickup truck ====\n",
      "     Reads the Bible line for line     \n",
      "     While sipping on     \n",
      "\n",
      "\n",
      "2. Like You Were Mine -  Jason Aldean :\n",
      "     Still feeling you like you never said goodbye     \n",
      "     Like you were mine     \n",
      "          \n",
      "==== Sometimes this take-me-back truck ====\n",
      "     Talks me into burning gas     \n",
      "     Past your house     \n",
      "\n",
      "\n",
      "3. Cop Car -  Sam Hunt :\n",
      "     We thought we had all night     \n",
      "     There was no need to rush     \n",
      "     That's when those cops     \n",
      "==== Came pulling up ====\n",
      "     And I thought     \n",
      "     Man  ain't this some shhhh     \n",
      "\n",
      "\n",
      "4. Cop Car (Acoustic) -  Sam Hunt :\n",
      "     We thought we had all night     \n",
      "     There  was no need to rush     \n",
      "     That's  when those cops     \n",
      "==== Came pulling up ====\n",
      "     And  I thought     \n",
      "     Man  ain't this some shhhh     \n",
      "\n",
      "\n",
      "5. Meija -  Porno for Pyros :\n",
      "     Everybody  count your money!     \n",
      "     Everybody  yeah  you better count your money!     \n",
      "     Where you going  Meija?     \n",
      "==== Took the car ====\n",
      "     Out for a drive     \n",
      "     Didn't come back     \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# code autoruns, not sure how to get it to wait for a user input\n",
    "\n",
    "user_query = query.value\n",
    "print(\"running query...\")\n",
    "\n",
    "query_embeddings = get_embeddings([user_query])[0]\n",
    "\n",
    "# Return X nearest neighbors\n",
    "nns = ann.get_nns_by_vector(query_embeddings, slider.value, include_distances=False)\n",
    "\n",
    "print(\"Top {} results for \\'{}\\'\".format(slider.value, query.value))\n",
    "for idx, item in enumerate(nns):\n",
    "    print(\"{}. {} - {}:\".format(idx+1, mapping[item][1], mapping[item][2]))\n",
    "    for x in range(item-3, item+3):\n",
    "        if x == item:\n",
    "            print(\"==== {} ====\".format(mapping[x][0]))\n",
    "        else:\n",
    "            print(\"     {}     \".format(mapping[x][0]))\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CS410 Project Bae Area",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
